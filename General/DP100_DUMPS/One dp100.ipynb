{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You train a mcahine learning model.\n",
    "    You must deploy the model as a real-time interence service for testing. The service for testing. The service requires \n",
    "    low CPU utilization and less than 48MB of RAM. The computer target for the deployed must initialize automatically while\n",
    "    minimizing cost and administrative overhead.\n",
    "    Which computer target should you use?\n",
    "    \n",
    "    A. Azure kubernets Services(AKS) inference cluster.\n",
    "    B. attached Azure Databricks cluster\n",
    "    C. Azure container interface (ACI)\n",
    "    D. Azure machine learning computer cluster\n",
    "    \n",
    "# Ans : C\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are training machine learning models in Azure machine learning. You use Hyperdrive to tune the hyperparameters.\n",
    "    In previous model training and tuning runs, many model showed similar performance.\n",
    "    You need to select an early termination policy that meet the following requirements.\n",
    "    \n",
    "        - Accounts for the performance of all the previous runs when evaluating the current run.\n",
    "        - Avoid comparing the current run with only the best performing run to date.\n",
    "    Which two early termination policies should you use? Each correct answer presents part of the solution.\n",
    "    \n",
    "    A. Default \n",
    "    B. Bandit\n",
    "    C. Median stopping \n",
    "    D. Truncation selection \n",
    "    \n",
    "# Ans: A, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are creating a classiication model for a banking company to identify possible instances of credit card fraud.\n",
    "    You plan to create the model in Azure Mcahine Leaning by using automated machine learning. \n",
    "    The training dataset that are using is highly unbalanced.\n",
    "    You need to evaluate the classification model.\n",
    "    Which primary metrix you use?\n",
    "    \n",
    "    A. AUC_weighted \n",
    "    B. accuracy\n",
    "    C. normalization_mean_absolute_error\n",
    "    D. spearman_correction \n",
    "    E. normalized_root_mean_squared_error\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You plan to use the Hyperdrive feature of Azure Machine Learning ot determine the optiaml hyperparameter values when training a modal.\n",
    "    You must use Hyperdrive to try combinations of the following hyperparameter values:\n",
    "        - learning rate: any value between 0.001 and 0.1\n",
    "        - batch size 16, 32, or 64\n",
    "    You Need to configure the search space for the Hyperdrive experiment.\n",
    "    Which two parameter expression should you use? Each correct answer presents part of the solution.\n",
    "\n",
    "    A. A uniform expression for learning_rate\n",
    "    B. A normal expression for batch_size\n",
    "    C. A choice expression for batch_size\n",
    "    D. A uniform expression for batch_size\n",
    "    E. A choice expression for learning_rate\n",
    "\n",
    "# Ans: A,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You use the Azure Machine Learning SDK to run a training experiment that trains a classification \n",
    "    model and calculate its accuracy metrics. \n",
    "    The model will be returned each month as new data is available.\n",
    "    You must register the model for use in a batch interface pipeline.\n",
    "    You need to register the model and ensure that the models created by subsequent returning experiment \n",
    "    and registered only if the accuracy is highest than the currently registered model.\n",
    "    \n",
    "    What are two possible ways to achieve the goal each correct answer present a complete solution.\n",
    "    \n",
    "    A. Register the model with the same name each time regardless of accuracy and always use the latest \n",
    "    version of the model in the batch interfacing pipeline.\n",
    "    \n",
    "    B. Specify a tag named accuracy with the accuracy metrics as a value when registering the model and \n",
    "    only register subsequent models if their accuracy is higher than the accuracy tag value of the currently \n",
    "    register model.\n",
    "    \n",
    "    C. Specify a property named accuracy with the accuracy Matrix as a value when registering the model and \n",
    "    only register subsequent models if their accuracy is higher than the accuracy Property value of the currently \n",
    "    register model. \n",
    "    \n",
    "    D. Specify the model Framework version when registered the model and only register subsequent models if this value is higher.\n",
    "    \n",
    "    E. Specify a different name for the model each time you register it\n",
    "    \n",
    "# Ans: B,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You plan to use a hyperdrive feature of Azure machine learning to determine the optimal hyperparameter values when \n",
    "    training a model.\n",
    "    You must use hyperdrive to try a combinations of the following hyperparameter values. You must not apply an early transmission\n",
    "        - learning_rate: Any value between 0.001 and 0.1\n",
    "        - batch_size: 16 32 or 64 \n",
    "    You need to configure the sampling method for the hyperdrive experiment.\n",
    "    Which two sampling model can you use? Each correct answer is a complete solution.\n",
    "    \n",
    "    A. Random sampling\n",
    "    B. Grid sampling\n",
    "    C. Bayesian sampling\n",
    "    D. No sampling\n",
    "    \n",
    "# Ans: No sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You have a dataset that includes home sales data for a city. The dataset includes the following columns.\n",
    "        name                        description\n",
    "        price               The sales price for the house \n",
    "        Bedrooms            The number of bedrooms in the house\n",
    "        size                The size of the house is square feet\n",
    "        HasGarage           A binary value indicating whether or not the house has a garage.\n",
    "        HomeType            The category of home for example apartment townhouse single family home.\n",
    "    \n",
    "    Each row in the dataset crossponds to an individual home sales transaction.\n",
    "    You need to use the automated machine learning to generate the best model for predicting the sales price\n",
    "    based on the feature of the house.\n",
    "    Which values should you use? To the answer, select the appropriate option in the answer area.\n",
    "    \n",
    "        Setting              value\n",
    "        Prediction task      # Fill in the blanks\n",
    "        Target column        # Fill in the blanks\n",
    "    \n",
    "# Ans:  \n",
    "    Setting              value\n",
    "    Prediction task      Regression\n",
    "    Target column        Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are preparing to build a deep learning convolutional neural network model for image classification. you create script\n",
    "    to train the model using CUDA drivces. \n",
    "    You must submit an experiment that run this script in the Azure machine learning workspace.\n",
    "    The following computer resources are available\n",
    "        - A machine surface device on which Microsoft Office has been installed. Corporate IT policies to prevent the installation \n",
    "        of additional software \n",
    "        - A computer instance named DS-workstation in the workspace with 2 CPUs and 8GB of Memory\n",
    "        - An Azure machine learning computer target name CPU-cluster with a CPU-based notes.\n",
    "        - An Azure machine learning computer target name GPU-cluster which show CPU and GPU-based nodes.\n",
    "        \n",
    "    You need to specify the computer resources to be used for learning the code to submit the experiment and the running the script\n",
    "    in order to minimise model training time.\n",
    "    Which resources should the data scientist use? To answer select the appropriate option in the answer area.\n",
    "    \n",
    "        Resource type                        option\n",
    "        Run code to submit the experiment    # Fill in the blanks\n",
    "        Run the training Script              # Fill in the blanks \n",
    "        \n",
    "        \n",
    "#  Ans:\n",
    "            Resource type                        option\n",
    "        Run code to submit the experiment    The cpu cluster compute target\n",
    "        Run the training Script              The gpu-compute cluster \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You plan to use hyperdrive to optimise the hyperparameters selected when training a model. You create the following code \n",
    "    to define options for the hyperparameter experiment:\n",
    "        import azureml.train.hyperdrive.parameter_expressions as pe\n",
    "        from azureml.train.hyperdrive import GridPArameterSampling, HyperDriveConfig\n",
    "        \n",
    "        param_sampling = GridPArameterSampling({\n",
    "            \"max_depth\" = pe.choice(6,7,8,9),\n",
    "            \"learning_rate\" = pe.choice(0.05,0.1,0.15)\n",
    "        })\n",
    "        hyperdrive_run_config = HyperDriveConfig(\n",
    "            estimator = estimator,\n",
    "            hyperparameter_sampling = param_sampling,\n",
    "            policy = None,\n",
    "            primary_metric_name = \"auc\",\n",
    "            primary_metric_goal = PrimaryHetricGoal.MAXIMIZE,\n",
    "            max_total_runs = 50,\n",
    "            max_concurrent_runs = 4\n",
    "        )\n",
    "        For each of the following statements select yes if the statement is true, otherwise select no.\n",
    "        \n",
    "        1. There will be 50 runs for this hyperparameter tuning experiment.\n",
    "        2. You can use the policy parameter in the HyperDriveConfig class to specify a security policy.\n",
    "        3. The experiment will create a run for every possible value for the learning rate parameter between 0.05 and 0.15.\n",
    "        \n",
    "# Ans: \n",
    "    Yes: 1   \n",
    "    No: 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You write a python script that preprocess data in a comma separated value(csv) file.\n",
    "    You plan to run the script as an Azure machine learning experiment.\n",
    "    The script loads the data and determines the number of row it contains using the following code.\n",
    "    \n",
    "    from azureml.cure import Run\n",
    "    import pandas as pd\n",
    "    \n",
    "    run = Run.get_context()\n",
    "    data = pd.read_csv('./data.csv')\n",
    "    rows = (len(data))\n",
    "    # record row_count matric here\n",
    "    ....\n",
    "    \n",
    "    You need to record the row count as a the matrix named row_count that can be returned using the get_matrics method of the Run object after the experiment \n",
    "    Run completes.\n",
    "    Which code should you use?\n",
    "    \n",
    "    A. run.log_table(row_count, rows)\n",
    "    B. run.upload_file(row_count, './data.csv')\n",
    "    C. run.log_row('row_count',rows)\n",
    "    D. run.tag('row_count', rows)\n",
    "    E. run.log('row_count',rows)\n",
    "\n",
    "# Ans: E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You use the Azure machine learning SDK in a notebook to run an experiment using a script file in a experiment folder.\n",
    "    The experiment fails.\n",
    "    You need to troubleshoot the field experiment.\n",
    "    What are two possible ways to achieve this goal? Each correct answer present a complete solution.\n",
    "    \n",
    "    A. Use that get_details_with_logs() method of the run object to display the experiment Run logs.\n",
    "    B. Use a get_output() method to run to the run object to retrieve the experiment run logs.\n",
    "    C. Use the get_matrics() method of the run object to retrieve the experimental run logs.\n",
    "    D. View the log file for the experiment run in the experiment folder.\n",
    "    E. View the logs for the experiment run in Azure Machine learning studio.\n",
    "    \n",
    "# Ans: A,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You use the Azure machine learning service to create a tabular dataset named training_data. You plan to use this dataset in a\n",
    "    training script. You create a variable that references the dataset using the following code:\n",
    "    \n",
    "    training_ds = workspace.datasets.get(\"training_data\")\n",
    "    \n",
    "    You define an estimator to run the script.\n",
    "    You need to set a correct property of the estimator to ensure that your script can access the training_data dataset.\n",
    "    Which property should you set?\n",
    "    \n",
    "    A. source_directory = training_ds\n",
    "    B. script_params = {\"--training_ds\":training_ds}\n",
    "    C. environment_defination = {\"training_data\":training_ds}\n",
    "    D. inputs = [training_ds.as_named_input('training_ds')]\n",
    "    \n",
    "# Ans: D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are developing a deep learning model by using Tensorflow. You plant to run the model training workload on an Azure machine learning computer instance.\n",
    "    You must use CUDA based model training.\n",
    "    You need to provision the computer instance.\n",
    "    Which two virtual machine size can you use? To answer select the appropriate Virtual Machine sizes in the answer area.\n",
    "    \n",
    "    Virtual machine size:  # fill in the blanks\n",
    "        \n",
    "           Name1             CPUs              GPUs             RAM          Resource disk\n",
    "        1. BASIC_AD           1                 -               0.75GB       20GB\n",
    "        2. STANDARD_D3_V2     4                 -               14GB         200GB\n",
    "        3. STANDARD_864_V3    64                -               412GB        1400GB\n",
    "        4. STANDARD_MINL5     64                -               512GB        2000GB\n",
    "        5. STANDARD_NC12      12                2               112GB        680GB\n",
    "        6. STANDARD_NC24      24                4               224GB        140GB\n",
    "        \n",
    "# Ans: 5,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You run and experiment that uses an AutoMLConfig class to define an automated machine learning task with a maximum of that of ten model training preparations\n",
    "    The task will attempt the fine the best performing model based on a matrix named accuracy.\n",
    "    You submit the experiment with the following code:\n",
    "            \n",
    "        from azureml.core.experiment import Experiment\n",
    "        automl_experiment = Experiment(ws, 'automl_experiment')\n",
    "        automl_run = automl_experiment.student(automa_config, show_output = True)\n",
    "        \n",
    "    You need to create python code that return the best model that is generated by the automated machine learning task.\n",
    "    Which code segment should you use?\n",
    "    \n",
    "    A. best_model = automl_run.get_output()[1]\n",
    "    B. best_model = automl_run.get_file_names()[1]\n",
    "    C. best_model = automl_run.get_details()\n",
    "    D. best_model = automl_run.get_matrics()\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You deploy a real-time inference service for a training model. \n",
    "    The deployed model supports a business-critical application and it is important to be able to monitor the data submitted to the web service\n",
    "    and the predictions the data and generates.\n",
    "    You need to implement a monitoring solution of the deployed model using minimal administrative effort.\n",
    "    What should you do?\n",
    "    \n",
    "    A. Create an ML Flow tracking URL that references the endpoint, and view the data logged by ML Flow.\n",
    "    B. Enable Asure application insights of for the service endpoint and view logged data in Azure portal.\n",
    "    C. View the experiments of the register model in Azure ML Studio.\n",
    "    D. View the log files generated by the experiment used to train the model.\n",
    "    \n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques : You create an Azure machine learning workspace. You are preparing a local Python environment on a laptop computer. You must to use the\n",
    "    laptop to connect to the workspace and run experiments.\n",
    "    You create the following config.json file.\n",
    "    {\n",
    "        \"workspace_name\":\"ml-workspace\"\n",
    "    }\n",
    "    You must use the Azure machine learning SDK to interact with data and experiment in the workspace.\n",
    "    You need to configure the config.json file to connect to the workspace from the Python environment.\n",
    "    Which two additional parameters must you need add to the config.json file in order to connect to the workspace? Each correct answer Presents part of the solution.\n",
    "    \n",
    "    A. key\n",
    "    B. login\n",
    "    C. region\n",
    "    D. subscription_id\n",
    "    E. resource_group\n",
    "    \n",
    "# Ans: D,E\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You create a new Azure subscription. No resources are provisioned in the subscription.\n",
    "    You need to create an Azure machine learning workspace.\n",
    "    What are three possible way to achieve this goal? Each correct answer presents a complete solution.\n",
    "    \n",
    "    A. Navigate to Azure machine learning Studio and creative workspace.\n",
    "    \n",
    "    B. Use the Azure Command line interface(CLI) with the Azure machine learning extension to call the AZ group create function with -– name and --location parameters,\n",
    "    and then The az ml workspace create function specifying -w and -g parameters for the workspace name and resource group.\n",
    "    \n",
    "    C. Use an Azure resources management template that include a Microsoft.MachineLearningServices/Workspace resource and it dependencies.\n",
    "    \n",
    "    D. Run python code that uses the Azure ml SDK library and call the workspace get method with name subscription_ID and resource_group parameters\n",
    "    \n",
    "    E. Run python code that uses the Azure ml SDK library and calls the workspace create method with name subscription_ID, resource_group and location parameters.\n",
    "    \n",
    "# Ans: A,B,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are using Azure machine learning to train machine learning models. You need to compute target on which the remotely run the training script.\n",
    "    You run the following python code:\n",
    "    \n",
    "    from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "    from azureml.core.compute_target import ComputeTargetException\n",
    "    the_cluster_name  = \"NewComputer\"\n",
    "    config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2', max_nodes=3)\n",
    "    the_cluster = ComputeTarget.create(ws, the_cluster_name, config)\n",
    "    \n",
    "    For each of the following statements, select yes if the statement is true otherwise select no.\n",
    "    \n",
    "    1. The compute is created in the same region as the Machine learning service workspace.\n",
    "    2. The compute resource created by the code is displayed as the computer cluster in Azure machine learning Studio.\n",
    "    3. The minimum number of nodes will be zero.\n",
    "    \n",
    "# Ans:\n",
    "    Yes: 1,2,3\n",
    "    No : -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You have a Azure bulb container that contains a set of TSV file. The Azure bulb container is registered as a datastore for an Azure machine learning service.\n",
    "    workspace. Each TSV file uses the same data schema.\n",
    "    You plan the aggregate data for all of the TSV files together and then register the aggregated data as the dataset in an Azure machine learning workspace by using \n",
    "    the Azure machine learning SDK for Python.\n",
    "    You run the following code.\n",
    "    \n",
    "    from azureml.core.workspace import workspace\n",
    "    from azureml.core.datastore import Datastore\n",
    "    from azureml.core.dataset import Dataset\n",
    "    import pandas as pd\n",
    "    datastore_paths = (datastore,'./data/*.tsv')\n",
    "    myDataset_1 = Dataset.File.from_files(path=datatstore_paths)\n",
    "    myDataset_2 = Dataset.Tabular.from_delimited_files(path=datastore_paths,separtor='\\t')\n",
    "        \n",
    "    For each of the following statement, select Yes if the statement is true. Otherwise select no.\n",
    "    \n",
    "    1. The MyDataset_1 dataset can be converted into a panda dataframe by using the following method:\n",
    "        using myDataset_1.to_pandas_dataframe()\n",
    "        \n",
    "    2. The myDataset_1 to_path() method return an array to file paths for all of the TSV files in the dataset.\n",
    "    \n",
    "    3. The myDataset_2 dataset can be converted into a Pandas dataframe by using the following method:\n",
    "        myDataset_2.to_pandas_dataframe()\n",
    "        \n",
    "# Ans: \n",
    "    Yes: 3\n",
    "    No: 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques:  You create an Azure machine learning computer resource to train models. The computer resource is configured as follows:\n",
    "            - Minimum notes: 2\n",
    "            - Maximum notes: 4\n",
    "    You must derese the minimum number of nodes are increased the maximum number of nodes to the following values:\n",
    "            - Minimum notes: 0\n",
    "            - Maximum notes:8 \n",
    "    You need to reconfigure the computer resource.\n",
    "    What are three possible ways to achieve this goal? Each correct answer present a complete solution.\n",
    "    \n",
    "    A. Use the Asure machine learning Studio.\n",
    "    B. Run the update machine of the Amlcomputer class in the Python SDK.\n",
    "    C. Use the Azure machine learning designer \n",
    "    D. Use the Azure portal\n",
    "    \n",
    "# Ans : 1, 2 ,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are hired as a data scientist at a winery.The previous data scientist used Azure machine learning.\n",
    "    You need to review the models and explain how each model makes decisions.\n",
    "    Which explainer modules should you use? To answer, select the appropriate options in the answer area.\n",
    "    \n",
    "    1. A random forest model for predicting the alcohol contain in wine give a set of convariates.             ## fill in the blanks\n",
    "    2. A Natural Language Processing model for analyzing field reports                                         ## fill in the blanks\n",
    "    3. An image classifier that determines the quality of the grape based upon its physical characteristics.   ## fill in the blanks\n",
    "    \n",
    "# Ans: \n",
    "    1. Tabular\n",
    "    2. Text\n",
    "    3. Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You plan to run a script as an experiment using a script Run configuration. The script uses modules from the script library\n",
    "    as well as several Python packages that are not typically install in the default Conda environment. \n",
    "    View plan to run the experiment on your local Workstation for small datasets and scale out the experiment by running it on more \n",
    "    powerful remote computer clusters for large datasets.\n",
    "    You need to ensure that the experiment Run successfully on local and remote computer with the least administrative effort.\n",
    "    What should you do?\n",
    "    \n",
    "    A. Always run the experiment with the estimator by using the default packages.\n",
    "    \n",
    "    B. Create a config yami file defining the conda packages that are required and save the file in the experiment folder.\n",
    "    \n",
    "    C. Create and register an environment that includes the required packages. Use this experiment for all experiment runs.\n",
    "    \n",
    "    D. Create a virtual machine (VM) with the required Python configuration and attach the VM as a compute target. Use the \n",
    "    computer target for all experiment Runs.\n",
    "    \n",
    "    E. Do not specify an environment in the run configuration for the experiment. Run the experiment by using the default and \n",
    "    environment.\n",
    "    \n",
    "# Ans: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques : You use Azure machine learning to train the register a model.\n",
    "    You must deploy the model into production as a real-time web service to an inference cluster named service-compute that the \n",
    "    IT department has created in the Azure machine learning workspace.\n",
    "    Client application consuming done deployed their service must be authenticated based on their Azure active directory service principal.\n",
    "    You need to write a script that uses the Azure machine learning SDK to deploy the model. The necessary modulus have been imported.\n",
    "    How should you compute the code? To answer, select the appropriate options in the answer area.\n",
    "    \n",
    "    ## Assume the necessary modules have been imported\n",
    "    deploy_target = #Fill in the blanks (ws,\"service-compute\")\n",
    "    deployment_config = (#Fill in the blanks).deploy_configuration(cpu_cores=1, memory_gb=1,\n",
    "                                                          (#Fill in the blanks))\n",
    "    service = Model.deploy(ws,'ml-service',\n",
    "                          [model], inference_config, deployment_config, deploy_target)\n",
    "    service.wait_for_deployment(show_output=True)\n",
    "\n",
    "Ans: \n",
    "    deploy_target = AksCompute (ws,\"service-compute\")\n",
    "    deployment_config = AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1,\n",
    "                                                          token_auth_enabled=True)\n",
    "    service = Model.deploy(ws,'ml-service',\n",
    "                          [model], inference_config, deployment_config, deploy_target)\n",
    "    service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You use Azure machine learning designer to create a real-time service endpoint. You have a single \n",
    "    Azure machine learning service compute resource.\n",
    "    You train the model and prepare the real-time pipeline for deployment.\n",
    "    You need to publish the inference pipeline as a web service.\n",
    "    Which computer type should you use?\n",
    "    \n",
    "    A. HDinsight\n",
    "    B. Azure Databricks \n",
    "    C. the existing machine learning computer resource\n",
    "    D. a new machine learning computer resource \n",
    "    E. Azure kubernets services\n",
    "\n",
    "# Ans : E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You are a data scientist working for a hotel booking website company. You use the Azure machine learning \n",
    "    service to train the model that identify faudulent transactions.\n",
    "    You must deploy the model as an Azure machine learning real-time web service using the Model.deploy method\n",
    "    in the Azure machine learning SDK. The deployed web service must return real-time protections of fraud based\n",
    "    on transaction data input.\n",
    "    \n",
    "    You need to create the script that is specified as the entry_script parameter for the inferenceConfig class \n",
    "    used to deploy the model.\n",
    "    What should the entry script do?\n",
    "    \n",
    "    A. Create a Conda environment for the web service compute and install the necessary Python packages \n",
    "    B. Register the model with appropriate tags and properties.\n",
    "    C. Start a note on the inference cluster where the web service is deployed.\n",
    "    D. Load the model and use it it to predict the labels from input data.\n",
    "    E. Specify the number of course and the amount of money required for the inference computer.\n",
    "    \n",
    "# Ans: D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: An organization creates and deploys a multi-class image classification deep learning model that uses a \n",
    "    set of labeled photographs. \n",
    "    The software engineering team reports there is a heavy inferencing load for the production web services \n",
    "    during the summer. The predictions web service for the model fails to meet demand despite having a fully-utilized\n",
    "    compute cluster where the web service is deployed.\n",
    "    You need to improve performance of the image classification web service with minimal downtime and minimal administrative \n",
    "    effort.\n",
    "    What should you advise the IT operations team to do?\n",
    "    \n",
    "    A. Create a new to compute cluster by using larger VM sizes for the notes, redeploy the web service to the cluster, and\n",
    "    update the DNS registrations for the service endpoint to point to the new cluster.\n",
    "    \n",
    "    B. Increase the nods count of the computer cluster where the web service is deployed.\n",
    "    \n",
    "    C. Increase the VM size of nodes in the computer cluster where the web service is deployed.\n",
    "    \n",
    "    D. Increase the minimum node count of the compute cluster where the web service is deployed.\n",
    "    \n",
    "# Ans: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You create a machine learning model by using the Azure machine learning designer. You publish the model \n",
    "    as a real-time service on an Azure kubernetes service (AKS) inference computer cluster. You make no changes\n",
    "    to the deploy endpoint configuration.\n",
    "    You need to provide application developers with the information they need to consume the endpoint.\n",
    "    Which two values should you provide the application developers? Each correct answer presents part of the solution.\n",
    "    \n",
    "    A. The name of the inference pipeline for the endpoint.\n",
    "    B. The URL of the endpoint \n",
    "    C. The name of the AKS cluster where the endpoint is hosted.\n",
    "    D. The run ID of the inference pipeline experiment for the endpoint.\n",
    "    E. The key for the endpoint \n",
    "    \n",
    "# Ans: B, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques:  You create a pipeline to designer to train a model that predicts automobile prices.\n",
    "    Because of non-linear relationship in the data the pipeline calculates the natural log (LN)\n",
    "    of the prices in the training data, trains a model to predict the natural log of Price value\n",
    "    and then calculates the exponential of the scored label to get the predicted price that.\n",
    "    \n",
    "    The training pipeline is shown in the exhibit.\n",
    "    \n",
    "    You create a real-time in inference pipeline from the training pipeline, as shown in the exhibit.\n",
    "    \n",
    "    You need to modify the inference pipeline to ensure that the web service returns the exponential of\n",
    "    the scored level as the predicted automobile price and that client applications are not required to\n",
    "    include a price value in the input values.\n",
    "    \n",
    "    Which three modification must you make to the inference pipeline? Each correct answer Present part of the solution.\n",
    "    \n",
    "    A. Remove the apply math operation module that replace price with its natural log from the data flow \n",
    "    B. Replace the web service input module with a data input that does not include the price Column.\n",
    "    C. Replace the training dataset module with a data input that does not include the price column.\n",
    "    D. Add a select columns module before the score model module to select all columns other than price.\n",
    "    E. Connect the output to the apply SQL transformation to the web service output module.\n",
    "    F. Remove the apply SQL transformation module from the data flow.\n",
    "    \n",
    "# Ans: C,D,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You create an Azure machine learning workspace and set up a development environment. You plan to train a deep neural network (DNN) by using the tensorflow \n",
    "    framework and by using estimator to submit training scripts.\n",
    "    You must optimise computation speed for training Runs.\n",
    "    You need to choose the appropriate estimator to use as well as the appropriate training compute target configuration.\n",
    "    Which value should you use? To answer, select the appropriate option in the answer area.\n",
    "    \n",
    "            parameter            value \n",
    "            Estimator            #Fill in the blanks \n",
    "            Training compute     #fill in the blanks\n",
    "\n",
    "# Ans:\n",
    "    parameter            value \n",
    "    Estimator            Tensorflow \n",
    "    Training compute     12 vCPV, 112GB memory, 680 GB SSD, 2 GPU, 24gb CPU memory\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You create a betch inference pipeline by using the Azure ML SDK. You configure the pipeline\n",
    "    parameters by executing the following code:\n",
    "        \n",
    "        from azureml.contain.pipline.steps import ParallelRunConfig\n",
    "        parallel_run_config = ParallelRunConfig(\n",
    "            source_directory = scripts_folder,\n",
    "            entry_script = \"batch_pipline.py\",\n",
    "            mini_batch_size=\"5\",\n",
    "            error_threshold=10,\n",
    "            output_actions = \"append-row\",\n",
    "            compute_target = compute_target,\n",
    "            Iogging_level='DEBUG',\n",
    "            node_count=4\n",
    "        )\n",
    "        \n",
    "    You need to obtain the output from the pipeline execution.\n",
    "    Where will you find the output?\n",
    "    \n",
    "    A. a file named parallel_run_step.txt located in the output folder\n",
    "    B. the activity log in the Azure portal for the machine learning workspace \n",
    "    C. the digit_identification.py script\n",
    "    D. the debug log\n",
    "    E. the inference clusters tab in machine learning studio\n",
    "    \n",
    "# Ans : B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You register a file dataset named csv_folder that references a folder. \n",
    "    The folder includes multiple, comma-separated values(csv) files in an Azure storage blob container. \n",
    "    \n",
    "    you plant to use the following code to run the script that loads data from the file dataset. You create and instantite the following variables.\n",
    "    \n",
    "    Variable                            Description \n",
    "    remote_cluster                      Retrieves the Azure machine learning compute cluster\n",
    "    WS                                  References the Azure machine learning workspace\n",
    "    \n",
    "    you have the following code:\n",
    "       \n",
    "        from azureml.train.estimator import Estimator\n",
    "        file_dataset = ws.datasets.get('csv_folder')\n",
    "        estimator = Estimator(source_directory=script_folder,\n",
    "                              \n",
    "                              \n",
    "                             compute_target=remote_cluster,\n",
    "                             entry_script='script.py'\n",
    "                             )\n",
    "        run = experiment.submit(config=estimator)\n",
    "        run.wait_for_completion(show_output=True)\n",
    "        \n",
    "        \n",
    "    you need to pass the dataset to ensure that the script can read and file it references.\n",
    "    Which code segment should you insert to replace the code comment?\n",
    "    \n",
    "    A. inputs=[file_dataset.as_named_input('training_files').as_mount()],\n",
    "    B. inputs=[file_datasets.as_named_input('training_files')],\n",
    "    C. inputs=[file_dataset.as_named_input('training_files').to_pandas_dataframe()],\n",
    "    D. script_params=('--training_files': file_dataset),\n",
    "    \n",
    "# Ans: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You create a script for training a machine learning model in Azure machine learning service.\n",
    "    You create estimator by running the following code.\n",
    "    \n",
    "    \n",
    "    For each of the following statement select Yes if the statement is true, otherwise select No.\n",
    "    \n",
    "    1. The estimator will look for the file is it needs to run an experiment in the training experiment \n",
    "    directory of the local compute environment\n",
    "    \n",
    "    2. The estimator will amount the local data folder folder and make it available to the script \n",
    "    through a parameter \n",
    "    \n",
    "    3. That train.py script file will be created if it does not exist\n",
    "    \n",
    "    4. The estimated Run can run scikit-learn experiments\n",
    "    \n",
    "# Ans: \n",
    "    Yes: 1, 2, 4\n",
    "    No: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You use Azure machine learning to deploy a model as a real-time web service.\n",
    "    You need to create an entry script for the service that ensure that the model is located when the service \n",
    "    starts and it is used to score new data as it it is received. \n",
    "    \n",
    "    Which function should you include in the Script? To answer, drag the appropriate option appropriate function \n",
    "    to the correct actions. Each function may be used once more than once, or not at all. You may need to drag the \n",
    "    split bar between panes or scroll to view content.\n",
    "    \n",
    "    NOTE: Each correct Selection is worth one point.\n",
    "        \n",
    "        Functions:\n",
    "            main(),  score(),   run(),  init(), predict()\n",
    "            \n",
    "        Actions                                   Function\n",
    "        Load the model when the service starts.   # fill in the blanks\n",
    "        Use the model to score new data.          # fill in the blanks\n",
    "        \n",
    "# Ans: \n",
    "        Actions                                   Function\n",
    "        Load the model when the service starts.   init()\n",
    "        Use the model to score new data.          predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You train a model and register in it your Azure machine learning workspace. You are ready to deploy the model as \n",
    "    a real-time web service.\n",
    "    You deploy the model to an Azure Kubernets(AKS) inference cluster, but the deployment fails because of error occurs,\n",
    "    when the services run the entry script that is associated with the model deployment.\n",
    "    \n",
    "    You need to debug the error by iterative modifying the code and reloading the service, without requiring a re-deployment\n",
    "    of the service for each code update.\n",
    "    What should you do?\n",
    "    \n",
    "    A. Create a local web service deployment configuration and deploy the model to a local docker container.\n",
    "    B. Created an Azure container instances (ACI) wab service deployment configuration and deploy the model on ACI.\n",
    "    C. Register in new version of the model and update the entry script to load the new version of the model from its registered path.\n",
    "    D. Modify the AKS service deployment configuration to enable application insight and re-deploy to AKS.\n",
    "    E. Add a breakpoint to the first line of the entry script and redeploy the service to AKS.     \n",
    "    \n",
    "# Ans: D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: You develop a train a machine learning model to predict fraudulent transactions for a hotel booking website.\n",
    "    Traffic to the site various considerably. The site experiences heavy traffic on Monday and Friday and much lower \n",
    "    traffic on other days holidays are also high web traffic days.\n",
    "    You need to deploy the model as an Azure machine learning real-time web service endpoint on compute that can dynamically \n",
    "    scale up and down to support demand.\n",
    "    Which deployment compute option should you use?\n",
    "    \n",
    "    A. Azure machine learning computer instance\n",
    "    B. attached Azure datebricks cluster.\n",
    "    C. Azure Kubernets service(AKS) inference cluster\n",
    "    D. Azure contain instance(ACI)\n",
    "    E. attached to virtual machine in a different region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        You have the following Azure subscription and Azure machine learning service workspace.\n",
    "            \n",
    "            Subscription                      workspace                  comment\n",
    "        385dfe5-4fe-4ad4-b977-3f86d92727c9    ml-default            This is the default subscription\n",
    "        5a5891d1-557a-4234-9b83-2e90412b1068  ml-project            The information required to uniquely indentify this workspace is\n",
    "                                                                    stored in the file config.json in the same folder as the Python script.\n",
    "        \n",
    "        You need to obtain air reference to the ML-project workspace.\n",
    "        Solution run the following python code.\n",
    "            \n",
    "            from azureml.core import Workspace\n",
    "            ws = workspace.from_config()\n",
    "        \n",
    "        does the solution meet the goal?\n",
    "        \n",
    "    A. Yes\n",
    "    B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        You have the following Azure subscription and Azure machine learning service workspace.\n",
    "            \n",
    "            Subscription                      workspace                  comment\n",
    "        385dfe5-4fe-4ad4-b977-3f86d92727c9    ml-default            This is the default subscription\n",
    "        5a5891d1-557a-4234-9b83-2e90412b1068  ml-project            The information required to uniquely indentify this workspace is\n",
    "                                                                    stored in the file config.json in the same folder as the Python script.\n",
    "        \n",
    "        You need to obtain air reference to the ML-project workspace.\n",
    "        Solution run the following python code.\n",
    "            \n",
    "            from azureml.core import Workspace\n",
    "            ws = workspace.get(name='ml-project')\n",
    "        \n",
    "        does the solution meet the goal?\n",
    "        \n",
    "    A. Yes\n",
    "    B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        You have the following Azure subscription and Azure machine learning service workspace.\n",
    "            \n",
    "            Subscription                      workspace                  comment\n",
    "        385dfe5-4fe-4ad4-b977-3f86d92727c9    ml-default            This is the default subscription\n",
    "        5a5891d1-557a-4234-9b83-2e90412b1068  ml-project            The information required to uniquely indentify this workspace is\n",
    "                                                                    stored in the file config.json in the same folder as the Python script.\n",
    "        \n",
    "        You need to obtain air reference to the ML-project workspace.\n",
    "        Solution run the following python code.\n",
    "            \n",
    "            from azureml.core import Workspace\n",
    "            ws = workspace.get(\n",
    "                name='ml-project',\n",
    "                subscription_id='5a5891d1-557a-4234-9b83-2e90412b1068'\n",
    "            )\n",
    "        \n",
    "        does the solution meet the goal?\n",
    "        \n",
    "    A. Yes\n",
    "    B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        You plan to use a python script to run an Azure machine learning experiment. The script creates a references \n",
    "        to the experiment Run contact, loads data from a file, identifies the set of unique values for the label column,\n",
    "        and completes the experiment run the experiment run.\n",
    "        \n",
    "        from azureml.core import Run\n",
    "        import pandas as pd\n",
    "        \n",
    "        run = Run.get_context()\n",
    "        data = pd.read_csv('data.csv')\n",
    "        label_vals = data['label'].unque()\n",
    "        ## Add code to record metircs here\n",
    "        run.complete()\n",
    "        \n",
    "        The experiment must record the unique labels in the data as matrics for the run that can be rewarded leter\n",
    "        \n",
    "        You must add code to the script to record the and unique label values as Run Matrics as the point indicated\n",
    "        by the comment. Solution replace the comment with the following code.\n",
    "        \n",
    "        run.log_list('Label Values', label_vals)\n",
    "        \n",
    "        Does the solution meet the goal?\n",
    "        \n",
    "        A. Yes\n",
    "        B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        You plan to use a python script to run an Azure machine learning experiment. The script creates a references \n",
    "        to the experiment Run contact, loads data from a file, identifies the set of unique values for the label column,\n",
    "        and completes the experiment run the experiment run.\n",
    "        \n",
    "        from azureml.core import Run\n",
    "        import pandas as pd\n",
    "        \n",
    "        run = Run.get_context()\n",
    "        data = pd.read_csv('data.csv')\n",
    "        label_vals = data['label'].unque()\n",
    "        ## Add code to record metircs here\n",
    "        run.complete()\n",
    "        \n",
    "        The experiment must record the unique labels in the data as matrics for the run that can be rewarded leter\n",
    "        \n",
    "        You must add code to the script to record the and unique label values as Run Matrics as the point indicated\n",
    "        by the comment. Solution replace the comment with the following code.\n",
    "        \n",
    "        run.log_table('Label Values', label_vals)\n",
    "        \n",
    "        Does the solution meet the goal?\n",
    "        \n",
    "        A. Yes\n",
    "        B. No\n",
    "\n",
    "# Ans: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        You plan to use a python script to run an Azure machine learning experiment. The script creates a references \n",
    "        to the experiment Run contact, loads data from a file, identifies the set of unique values for the label column,\n",
    "        and completes the experiment run the experiment run.\n",
    "        \n",
    "        from azureml.core import Run\n",
    "        import pandas as pd\n",
    "        \n",
    "        run = Run.get_context()\n",
    "        data = pd.read_csv('data.csv')\n",
    "        label_vals = data['label'].unque()\n",
    "        ## Add code to record metircs here\n",
    "        run.complete()\n",
    "        \n",
    "        The experiment must record the unique labels in the data as matrics for the run that can be rewarded leter\n",
    "        \n",
    "        You must add code to the script to record the and unique label values as Run Matrics as the point indicated\n",
    "        by the comment. Solution replace the comment with the following code.\n",
    "        \n",
    "        for label_val in label_vals:\n",
    "            run.log('Label Values', label_val)\n",
    "        \n",
    "        Does the solution meet the goal?\n",
    "        \n",
    "        A. Yes\n",
    "        B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        you are using Azure machine learning to run the experiment that trains a classification model.\n",
    "        \n",
    "        You want to use hyperdrive to find parameters that optimise the AUC Matrics for the model. You configure the hyperDriveConfig\n",
    "        for the experiment by running the following code.\n",
    "        \n",
    "        hyperdrive = HyperDriveConfig(estimator=your_estimator,\n",
    "                                     hyperperameter_sampling=your_params,\n",
    "                                      policy=policy,\n",
    "                                      primary_metric_name=\"AUC\",\n",
    "                                      primary_metric_goal = PrimaryMetrizational.MAXIMIZE,\n",
    "                                      max_total_run=6,\n",
    "                                      max_concurrent_run=4\n",
    "                                     )\n",
    "        \n",
    "        You plan to use that configuration to run the script that trains a random forest model and then test if with validation data.\n",
    "        The label values for the validation data are stored in a variable named y_test variable, and the predicted probabilities from\n",
    "        the model are stored in a variable named y_predicted.\n",
    "        \n",
    "        You need to add logging to the script to allow Hyperdrive to optimise parameters for the AUC Matric.\n",
    "        \n",
    "        solution run the following code:\n",
    "        \n",
    "        import json, os\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        ## code to train model emitted\n",
    "        auc = roc_auc_score(y_test, y_predicted)\n",
    "        os.mkdir(\"Output\", exist_ok=True)\n",
    "        with open('output/AUC.txt','w') as file_cur:\n",
    "            file_cur.write(auc)\n",
    "        \n",
    "        Does the solution meet the goal?\n",
    "        \n",
    "        A. Yes\n",
    "        B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        you are using Azure machine learning to run the experiment that trains a classification model.\n",
    "        \n",
    "        You want to use hyperdrive to find parameters that optimise the AUC Matrics for the model. You configure the hyperDriveConfig\n",
    "        for the experiment by running the following code.\n",
    "        \n",
    "        hyperdrive = HyperDriveConfig(estimator=your_estimator,\n",
    "                                     hyperperameter_sampling=your_params,\n",
    "                                      policy=policy,\n",
    "                                      primary_metric_name=\"AUC\",\n",
    "                                      primary_metric_goal = PrimaryMetrizational.MAXIMIZE,\n",
    "                                      max_total_run=6,\n",
    "                                      max_concurrent_run=4\n",
    "                                     )\n",
    "        \n",
    "        You plan to use that configuration to run the script that trains a random forest model and then test if with validation data.\n",
    "        The label values for the validation data are stored in a variable named y_test variable, and the predicted probabilities from\n",
    "        the model are stored in a variable named y_predicted.\n",
    "        \n",
    "        You need to add logging to the script to allow Hyperdrive to optimise parameters for the AUC Matric.\n",
    "        \n",
    "        solution run the following code:\n",
    "        \n",
    "        import numpy as np\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        from azureml.core_run import Run\n",
    "        run = Run.get_context()\n",
    "        ## code to train model emitted\n",
    "        auc = roc_auc_score(y_test, y_predicted)\n",
    "        run.log('AUC', np.float(auc))\n",
    "        \n",
    "        Does the solution meet the goal?\n",
    "        \n",
    "        A. Yes\n",
    "        B. No\n",
    "\n",
    "# Ans: A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ques: \n",
    "    NOTE: This question is a part of a series of questions that present the same scenario. Each question in the \n",
    "        series contain a unique solution that might meet the started goals. Some questions sets might have more \n",
    "        than one correct solution. While other might not have a correct solution,\n",
    "        \n",
    "        After you answer a question in the section you will not be able to return to it. As a result, these questions\n",
    "        will not appear in the review screen.\n",
    "        \n",
    "        you are using Azure machine learning to run the experiment that trains a classification model.\n",
    "        \n",
    "        You want to use hyperdrive to find parameters that optimise the AUC Matrics for the model. You configure the hyperDriveConfig\n",
    "        for the experiment by running the following code.\n",
    "        \n",
    "        hyperdrive = HyperDriveConfig(estimator=your_estimator,\n",
    "                                     hyperperameter_sampling=your_params,\n",
    "                                      policy=policy,\n",
    "                                      primary_metric_name=\"AUC\",\n",
    "                                      primary_metric_goal = PrimaryMetrizational.MAXIMIZE,\n",
    "                                      max_total_run=6,\n",
    "                                      max_concurrent_run=4\n",
    "                                     )\n",
    "        \n",
    "        You plan to use that configuration to run the script that trains a random forest model and then test if with validation data.\n",
    "        The label values for the validation data are stored in a variable named y_test variable, and the predicted probabilities from\n",
    "        the model are stored in a variable named y_predicted.\n",
    "        \n",
    "        You need to add logging to the script to allow Hyperdrive to optimise parameters for the AUC Matric.\n",
    "        \n",
    "        solution run the following code:\n",
    "        \n",
    "        import numpy as np\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        ## code to train model emitted\n",
    "        auc = roc_auc_score(y_test, y_predicted)\n",
    "        print(np.float(auc))\n",
    "        \n",
    "        Does the solution meet the goal?\n",
    "        \n",
    "        A. Yes\n",
    "        B. No\n",
    "\n",
    "# Ans: B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
